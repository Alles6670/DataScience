# Backpropagation
  #### 입력값 x, bias값 b가 있고 [g(x) = wx, f(x) = wx + b] 라 할때,
  #### 이 신경망을 학습 시키기 위해서는 각 w, x, b 가 f(x)에 미치는 영향도를 알아야하고,
  #### f(x)값을 각 입력 값인 w, x, b로 미분한 값을 알아야 한다.(편미분)
  #### 이 편미분 값을 통하여 각 w(가중치)에 대해Cost함수를 미분한 값과 learning rate를 이용하여 w를 업데이트 해준다.
